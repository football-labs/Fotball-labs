name: Ejecutar script de Scrape

on:
  schedule:
    # Se ejecuta cada martes y viernes a las 08:00 UTC
    - cron: '0 8 * * 2,5'
  workflow_dispatch: # Permite ejecutar manualmente el workflow

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Necesario para hacer commit en el repo

    steps:
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install pandas cloudscraper bs4 requests

      - name: Ejecutar script de Scrape
        run: python scripts/leagues_scrape.py

      - name: Commit y Push del archivo CSV generado
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Actualizar grouped_stats.csv [skip ci]"
          branch: main   # Cambia si tu rama principal no se llama 'main'
          file_pattern: ./data/grouped_stats.csv
          commit_user_name: GitHub Actions Bot
          commit_user_email: actions@github.com
          commit_author: GitHub Actions Bot <actions@github.com>
