# Import des libraries / Importing librairies / Importaci√≥n de bibliotecas
import re
import time
from typing import Tuple, List, Dict, Any
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException, StaleElementReferenceException, WebDriverException, InvalidSessionIdException, NoSuchWindowException
from urllib.parse import urlparse, urljoin
from selenium.webdriver.common.action_chains import ActionChains
import pandas as pd
from pprint import pprint
from pathlib import Path
from selenium.webdriver.chrome.service import Service
from urllib.parse import urlparse

## Partie servant pour le scraping des donn√©es / Part used for data scraping / Parte utilizada para el scraping de datos

# Initialisation du driver en mettant les options d√©sir√©s / Initialising the driver by setting the desired options / Inicializaci√≥n del controlador configurando las opciones deseadas
def make_driver(headed: bool = True) -> webdriver.Chrome:
    is_ci = os.getenv("GITHUB_ACTIONS") == "true"

    chrome_options = Options()
    # Fen√™tre raisonnable
    chrome_options.add_argument("--window-size=1366,900")

    # üëâ en CI, forcer headless + flags robustes
    if is_ci or not headed:
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--no-sandbox")   
        chrome_options.add_argument("--hide-scrollbars")
        chrome_options.add_argument("--force-device-scale-factor=1")
        chrome_options.add_argument("--lang=fr-FR")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 14_0) "
                                    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    else:
        chrome_options.add_argument("--lang=fr-FR")

    chrome_options.page_load_strategy = "eager"

    # Moins de traces d‚Äôautomation
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    drv = webdriver.Chrome(options=chrome_options)

    drv.set_page_load_timeout(60 if is_ci else 40)
    drv.set_script_timeout(60 if is_ci else 40)
    drv.implicitly_wait(0) 

    # Petites contres-mesures d‚Äôautomatisation
    try:
        drv.execute_cdp_cmd(
            "Page.addScriptToEvaluateOnNewDocument",
            {"source": """
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                Object.defineProperty(navigator, 'languages', {get: () => ['fr-FR','fr','en-US','en']});
                Object.defineProperty(navigator, 'platform', {get: () => 'MacIntel'});
                Object.defineProperty(navigator, 'vendor', {get: () => 'Google Inc.'});
            """}
        )
    except Exception:
        pass

    return drv


# Helpers sur les essais
def get_with_retries(driver, url: str, tries: int = 3, sleep_s: float = 1.0):
    last_err = None
    for i in range(tries):
        try:
            driver.get(url)
            return
        except TimeoutException as e:
            last_err = e
            try:
                # tenter un stop de chargement si bloqu√©
                driver.execute_script("window.stop();")
            except Exception:
                pass
            time.sleep(sleep_s)
    if last_err:
        raise last_err


# Fermeture de la page des cookies / Closing the cookies page / Cierre de la p√°gina de cookies
def handle_cookies(driver, accept: bool = True, timeout: int = 2) -> bool:
    # R√©cup√©ration du driver en laissant du Timeout pour laisser le temps de raffraichir la page / Retrieving the driver by leaving a timeout to allow time to refresh the page / Recuperaci√≥n del controlador dejando un tiempo de espera para que se actualice la p√°gina
    wait = WebDriverWait(driver, timeout)
    btn_id = "onetrust-accept-btn-handler" if accept else "onetrust-reject-all-handler"
    banner_sel = "div.ot-sdk-container[role='dialog'],#onetrust-banner-sdk,#onetrust-consent-sdk,#onetrust-button-group-parent"
    fallback_xp = ("//button[normalize-space()='I Accept' or contains(.,'Accept')]" if accept
                   else "//button[normalize-space()='Reject All' or contains(.,'Reject')]")

    # Recherche d'une banni√®re de cookie visible / Search for a visible cookie banner / B√∫squeda de un banner de cookies visible
    def banner_visible(drv):
        try:
            return any(el.is_displayed() for el in drv.find_elements(By.CSS_SELECTOR, banner_sel))
        except Exception:
            return False

    if not banner_visible(driver):
        return True
    
    # Si la banni√®re de cookie est visible, on cherche √† fermer cette page / If the cookie banner is visible, we try to close this page / Si el banner de cookies est√° visible, se intenta cerrar esta p√°gina
    frames = [None] + driver.find_elements(By.CSS_SELECTOR, "iframe,frame")
    clicked = False
    for fr in frames:
        try:
            if fr:
                driver.switch_to.frame(fr)
            btns = driver.find_elements(By.ID, btn_id) or driver.find_elements(By.XPATH, fallback_xp)
            if btns:
                try:
                    btns[0].click()
                except ElementClickInterceptedException:
                    driver.execute_script("arguments[0].click();", btns[0])
                clicked = True
                break
        except Exception:
            continue
        finally:
            try:
                driver.switch_to.default_content()
            except Exception:
                pass

    # Attendre la disparition de la banni√®re / Wait for the banner to disappear / Esperar a que desaparezca el banner
    try:
        WebDriverWait(driver, timeout).until(lambda d: not banner_visible(d))
    except TimeoutException:
        pass

    return not banner_visible(driver) or clicked

# Fonction pour cliquer sur l'onglet Statistiques des √âquipes / Function to click on the Team Statistics tab / Funci√≥n para hacer clic en la pesta√±a
def click_team_statistics(driver, timeout: int = 2) -> None:
    # Attente du driver / Waiting for driver / Esperando el controlador
    wait = WebDriverWait(driver, timeout)

    def _click_in_current_context():
        # Attendre la barre de navigation / Waiting for sub navigation / Esperar la barra de navegaci√≥n
        nav = wait.until(EC.presence_of_element_located((By.ID, "sub-navigation")))
        links = nav.find_elements(By.CSS_SELECTOR, "a[href*='/teamstatistics/']")
        if not links:
            links = nav.find_elements(
                By.XPATH,
                ".//a[normalize-space()='Statistiques des √âquipes' or contains(., 'Statistiques des √âquipes')]"
            )
        if not links:
            raise TimeoutException("Lien 'teamstatistics' introuvable dans #sub-navigation.")

        link = links[0]
        # S'assurer qu'il est cliquable / Ensure that it is clickable / Aseg√∫rate de que se pueda hacer clic en √©l.
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", link)
        try:
            wait.until(EC.element_to_be_clickable(link)).click()
        except ElementClickInterceptedException:
            # Tentative via JS si un overlay g√™ne / Attempt via JS if an overlay is interfering / Intento mediante JS si una superposici√≥n interfiere
            driver.execute_script("arguments[0].click();", link)
        except Exception:
            ActionChains(driver).move_to_element(link).pause(0.2).click(link).perform()
    try:
        driver.switch_to.default_content()
    except Exception:
        pass

    try:
        _click_in_current_context()
    except Exception as e:
        # Fallback : tester dans d'√©ventuels iframes / Fallback: test in any iframes / Fallback: probar en posibles iframes
        frames = driver.find_elements(By.CSS_SELECTOR, "iframe,frame")
        clicked = False
        for fr in frames:
            try:
                driver.switch_to.frame(fr)
                _click_in_current_context()
                clicked = True
                break
            except Exception:
                continue
            finally:
                try:
                    driver.switch_to.default_content()
                except Exception:
                    pass
        if not clicked:
            raise e

    # V√©rifier que l'onglet est bien ouvert / Check that the tab is open / Comprueba que la pesta√±a est√© bien abierta
    def on_team_stats(drv):
        if "/teamstatistics/" in (drv.current_url or ""):
            return True
        try:
            sel = drv.find_elements(By.CSS_SELECTOR, "#sub-navigation a[href*='/teamstatistics/'].selected")
            return len(sel) > 0
        except Exception:
            return False

    wait.until(on_team_stats)

# R√©cup√©rer la liste des √©quipes √† partir de l'url du championnat / Retrieve the list of teams from the championship URL / Recuperar la lista de equipos a partir de la URL del campeonato
def _clean_team_text(txt: str) -> str:
    # Normalise les noms / Normalises names / Normaliza los nombres
    txt = re.sub(r"^\s*\d+\.\s*", "", (txt or "").strip())
    txt = re.sub(r"\s+", " ", txt)
    return txt

# Si aucun texte n'est visible, on donne le nom issu du lien url / If no text is visible, the name from the URL link is given / Si no se ve ning√∫n texto, se muestra el nombre del enlace URL
def _name_from_href_fallback(href: str) -> str:
    try:
        last = href.rstrip("/").split("/")[-1]
        last = re.sub(r"^[a-z]{2,}-", "", last)
        parts = [p for p in last.split("-") if p]
        # On r√©cup√®re le nom depuis l'url de l'√©quipe associ√© / We retrieve the name from the associated team's URL / Se recupera el nombre de la URL del equipo asociado
        parts = [p.capitalize() for p in parts]
        # Recolle avec tirets si le nom contient des compos√©s / Rejoin with hyphens if the name contains compounds / Recoloca con guiones si el nombre contiene compuestos
        if len(parts) > 1:
            out = []
            i = 0
            while i < len(parts):
                if parts[i] == "Saint" and i + 1 < len(parts):
                    out.append(f"Saint-{parts[i+1]}")
                    i += 2
                else:
                    out.append(parts[i])
                    i += 1
            return " ".join(out)
        return parts[0] if parts else ""
    except Exception:
        return ""

# On extrait les informations de chaque √©quipe afin d'acc√©der dans un second temps leurs informations associ√©es / Information is extracted from each team so that their associated information can be accessed at a later stage / Se extrae la informaci√≥n de cada equipo para acceder posteriormente a su informaci√≥n asociada 
def extract_team_basic_info_from_summary(driver, timeout: int = 2, min_rows: int = 8):
    # Attente du driver / Waiting for the driver / Esperando el controlador
    wait = WebDriverWait(driver, timeout)

    # S'assurer que l‚Äôonglet "G√©n√©ral" est actif / Ensure that the ‚ÄòGeneral‚Äô tab is active / Aseg√∫rese de que la pesta√±a ¬´General¬ª est√© activa
    wait.until(EC.presence_of_element_located((By.ID, "stage-team-stats")))
    try:
        summary_tab = driver.find_element(By.CSS_SELECTOR, '#stage-team-stats-options a[href="#stage-team-stats-summary"]')
        if "selected" not in (summary_tab.get_attribute("class") or ""):
            summary_tab.click()
    except Exception:
        pass

    # Attendre que des lignes soient pr√©sentes / Wait until lines are present / Esperar a que haya l√≠neas
    def _anchors():
        return driver.find_elements(By.CSS_SELECTOR, "#top-team-stats-summary-content a.team-link")

    wait.until(lambda d: len(_anchors()) >= 1)
    for _ in range(10):
        n1 = len(_anchors())
        time.sleep(0.2)
        n2 = len(_anchors())
        if n2 == n1 and n2 >= min_rows:
            break

    anchors = _anchors()
    if not anchors:
        raise TimeoutException("Aucun lien d'√©quipe trouv√©.")

    parsed = urlparse(driver.current_url)
    origin = f"{parsed.scheme}://{parsed.netloc}"

    results = []
    for i in range(len(anchors)):
        # Re-r√©cup√©rer l'√©l√©ment √† chaque it√©ration / Retrieve the element again at each iteration / Recuperar el elemento en cada iteraci√≥n
        try:
            a = _anchors()[i]
        except Exception:
            # Si l‚Äôindex a chang√©, reprendre depuis le d√©but / If the index has changed, start again from the beginning / Si el √≠ndice ha cambiado, volver a empezar desde el principio
            anchors = _anchors()
            if i >= len(anchors):
                continue
            a = anchors[i]
        try:
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});", a)
            time.sleep(0.05)
        except Exception:
            pass

        # R√©cup√®ration de l'URL / URL retrieval / Recuperaci√≥n de la URL
        href_raw = (a.get_attribute("href") or a.get_attribute("data-href") or "").strip()
        href = urljoin(origin, href_raw)

        # ID d'√©quipe / Team ID / ID del equipo
        m = re.search(r"/teams/(\d+)/", href)
        if not m:
            # Si pas d'ID, ignorer la ligne / If no ID, skip the line / Si no hay ID, ignorar la l√≠nea
            continue
        team_id = int(m.group(1))

        # R√©cup√©ration du Nom d'√©quipe / Recovering the Team Name / Recuperaci√≥n del nombre del equipo
        team_name = ""
        for getter in ("text", "innerText", "textContent"):
            try:
                if getter == "text":
                    txt = a.text
                else:
                    txt = a.get_attribute(getter)
                team_name = _clean_team_text(txt or "")
                if team_name:
                    break
            except StaleElementReferenceException:
                try:
                    a = _anchors()[i]
                    if getter == "text":
                        txt = a.text
                    else:
                        txt = a.get_attribute(getter)
                    team_name = _clean_team_text(txt or "")
                    if team_name:
                        break
                except Exception:
                    continue
            except Exception:
                continue

        if not team_name:
            # R√©cup√®rer le nom d'√©quipe depuis l'url si cela n'a pas √©t√© fait auparavant / Retrieve the team name from the URL if this has not been done previously / Recuperar el nombre del equipo desde la URL si no se ha hecho anteriormente
            team_name = _name_from_href_fallback(href)

        results.append({
            "team_id": team_id,
            "team_name": team_name,
            "team_url": href,
        })

    # Enlever doublons si besoin / Remove duplicates if necessary / Eliminar duplicados si es necesario
    uniq, seen = [], set()
    for row in results:
        if row["team_id"] not in seen:
            uniq.append(row)
            seen.add(row["team_id"])

    return uniq

# Extraire les 5 meilleurs joueurs de chaque √©quipe / Pick the top 5 players from each team / Seleccionar a los 5 mejores jugadores de cada equipo
def extract_top5_ratings_from_team(driver, team_url: str, timeout: int = 4) -> dict:
    # On normalise le nom d'√©quipe / We standardise the team name / Se normaliza el nombre del equipo
    def _clean_name(txt: str) -> str:
        if not txt: return ""
        txt = txt.replace("\xa0", " ")
        txt = re.sub(r"^\s*\d+[\.\)]?\s*", "", txt)
        txt = re.sub(r"\s{2,}", " ", txt)
        return txt.strip()

    # On r√©cup√®re l'url de l'√©quipe / We retrieve the team's URL / Recuperamos la URL del equipo.
    driver.get(team_url)
    try:
        handle_cookies(driver, accept=False, timeout=2)
    except Exception:
        pass

    # On attend le driver et on cherche le tableau des joueurs / We wait for the driver and look for the players' table / Esperamos al conductor y buscamos la tabla de jugadores
    wait = WebDriverWait(driver, timeout)
    try:
        wait.until(EC.presence_of_element_located((By.ID, "stage-team-stats")))
        tab = driver.find_element(By.CSS_SELECTOR, '#stage-team-stats-options a[href="#stage-team-stats-summary"]')
        if "selected" not in (tab.get_attribute("class") or ""):
            try: tab.click()
            except Exception: driver.execute_script("arguments[0].click();", tab)
    except Exception:
        pass

    try:
        driver.execute_script("document.querySelector('#statistics-table-summary')?.scrollIntoView({block:'center'});")
    except Exception:
        pass

    wait.until(EC.presence_of_element_located(
        (By.CSS_SELECTOR, "#top-player-stats-summary-grid #player-table-statistics-body"))
    )

    rows = driver.find_elements(
        By.CSS_SELECTOR,
        "#top-player-stats-summary-grid #player-table-statistics-body > tr:not(.not-current-player)"
    )

    # Recherche du nom des 5 meilleurs joueurs par √©quipe en omettant les joueurs plus au club / Search for the names of the top 5 players per team, excluding players who are no longer with the club / Buscar los nombres de los 5 mejores jugadores por equipo, omitiendo a los jugadores que ya no est√°n en el club
    names = []
    for tr in rows:
        name = ""
        for sel in ["td.grid-abs a.player-link span.iconize",
                    "td.grid-ghost-cell a.player-link span.iconize",
                    "a.player-link"]:
            try:
                name = tr.find_element(By.CSS_SELECTOR, sel).text
                break
            except Exception:
                continue
        name = _clean_name(name)
        if name:
            names.append(name)
            if len(names) == 5:
                break
    while len(names) < 5: names.append("")
    return {
        "1st_best_player": names[0],
        "2nd_best_player": names[1],
        "3rd_best_player": names[2],
        "4th_best_player": names[3],
        "5th_best_player": names[4],
    }

# On extrait le nom de la formation type ainsi que les XI type / We extract the name of the typical formation and the typical starting XI / Se extrae el nombre de la formaci√≥n tipo y el XI tipo
def extract_formation_and_xi_from_team(
    driver,
    team_url: str,
    timeout: int = 6,
    reuse_current: bool = True
) -> dict:
    
    # On r√©cup√®re la page r√©cup√©r√© pr√©cedemment / We retrieve the previously retrieved page / Recuperamos la p√°gina recuperada anteriormente
    def _same_page(u1: str, u2: str) -> bool:
        try:
            p1, p2 = urlparse(u1), urlparse(u2)
            return (p1.netloc == p2.netloc) and (p1.path == p2.path)
        except Exception:
            return False
            
    # On r√©cup√®re la position des joueurs sur le XI type / We retrieve the players' positions on the typical XI / Se recupera la posici√≥n de los jugadores en el XI tipo
    def _parse_pos(style: str) -> str:
        # Position sur le XI : ex: "top: 75%; left: 55%;" / Position on the XI: e.g. ‚Äòtop: 75%; left: 55%;‚Äô / Posici√≥n en el XI: por ejemplo: ¬´top: 75%; left: 55%;¬ª
        if not style:
            return ""
        m_top  = re.search(r"top\s*:\s*([\d\.]+)\s*%",  style, flags=re.I)
        m_left = re.search(r"left\s*:\s*([\d\.]+)\s*%", style, flags=re.I)
        if not (m_top and m_left):
            return ""
        top  = re.sub(r"\.0+$", "", m_top.group(1))
        left = re.sub(r"\.0+$", "", m_left.group(1))
        return f"{top}; {left}"

    # Retrouve l'url de l'√©quipe si besoin / Find the team's URL if necessary / Busca la URL del equipo si es necesario
    cur = driver.current_url or ""
    if (not reuse_current) or (not _same_page(cur, team_url)):
        driver.get(team_url)
        try:
            handle_cookies(driver, accept=False, timeout=2)
        except Exception:
            pass

    # Attente du driver / Waiting for the driver / Esperando el controlador
    try:
        driver.switch_to.default_content()
    except Exception:
        pass
    wait = WebDriverWait(driver, timeout)

    # Cherche la table de la formation / Find the formation table Busca la tabla de formaci√≥n
    try:
        wait.until(EC.presence_of_element_located((By.ID, "stage-team-stats")))
        tab = driver.find_element(By.CSS_SELECTOR, '#stage-team-stats-options a[href="#stage-team-stats-summary"]')
        if "selected" not in (tab.get_attribute("class") or ""):
            try:
                tab.click()
            except Exception:
                driver.execute_script("arguments[0].click();", tab)
    except Exception:
        pass

    try:
        driver.execute_script("window.scrollTo(0,0);")
        driver.execute_script("document.querySelector('#team-formations')?.scrollIntoView({block:'center'});")
        driver.execute_script("window.dispatchEvent(new Event('scroll'));")
    except Exception:
        pass

    # Attente du chargement de la page / Waiting for page to load / Esperando a que se cargue la p√°gina
    try:
        wait.until(EC.presence_of_element_located((By.ID, "team-formations")))
    except TimeoutException:
        # Dernier recours : re-scroll / Last resort: re-scroll / √öltimo recurso: volver a desplazarse
        try:
            driver.execute_script("document.querySelector('#team-formations')?.scrollIntoView({block:'center'});")
        except Exception:
            pass

    # On s'assure qu'on a bien le XI type de la saison / We make sure we have the right starting XI for the season / Nos aseguramos de tener el XI tipo de la temporada
    try:
        saison_btn = driver.find_element(
            By.CSS_SELECTOR,
            '#team-formations-filter-type .listbox.left a.option[data-value="2"]'
        )
        if "selected" not in (saison_btn.get_attribute("class") or ""):
            saison_btn.click()
            time.sleep(0.05)
    except Exception:
        pass 

    # Selectionne la 1√®re tactique / Select the first tactic / Selecciona la primera t√°ctica
    formation_type = ""
    try:
        sel_el = driver.find_element(By.CSS_SELECTOR, '#team-formations-filter-formation select.filter-drop')
        select = Select(sel_el)
        if select.options:
            first = select.options[0]
            # R√©cup√®re le nom de la formation / Retrieves the name of the formation / Recupera el nombre de la formaci√≥n.
            formation_type = (first.get_attribute("data-source") or "").strip()
            if not formation_type:
                txt = (first.text or "").strip()
                m = re.match(r"^(\d+)", txt)
                if m:
                    formation_type = m.group(1)
            # On raffraichit la page si besoin / Refresh the page if necessary / Actualiza la p√°gina si es necesario.
            if not first.is_selected():
                select.select_by_index(0)
                time.sleep(0.05)
    except Exception:
        pass

    # On s'assure que la liste des joueurs est disponible / We ensure that the list of players is available / Nos aseguramos de que la lista de jugadores est√© disponible
    def _ul_count() -> int:
        return len(driver.find_elements(
            By.CSS_SELECTOR,
            "#team-formations-content .team-pitch-formation ul.player-wrapper"
        ))

    for _ in range(4):
        if _ul_count() > 0:
            break
        try:
            driver.execute_script("window.dispatchEvent(new Event('scroll'));")
            driver.execute_script("document.querySelector('#team-formations-content')?.scrollIntoView({block:'center'});")
        except Exception:
            pass
        time.sleep(0.08)

    wait.until(lambda d: _ul_count() > 0)

    # R√©cup√®re le nom des 11 joueurs et leur position / Retrieve the names of the 11 players and their positions / Recupera los nombres de los 11 jugadores y su posici√≥n
    players_uls = driver.find_elements(
        By.CSS_SELECTOR,
        "#team-formations-content .team-pitch-formation ul.player-wrapper"
    )

    players = []
    for ul in players_uls[:11]:
        # Nom / Name / Nombre
        try:
            name_el = ul.find_element(By.CSS_SELECTOR, "a.player-link.player-name")
            name = (name_el.text or name_el.get_attribute("textContent") or "").strip()
        except Exception:
            name = ""
        # Position / Position / Posici√≥n
        pos = _parse_pos(ul.get_attribute("style") or "")
        players.append((name, pos))

    # Compl√©ter si < 11 / Complete if < 11 / Completar si < 11
    while len(players) < 11:
        players.append(("", ""))

    # On ajoute les informations dans les noms de colonnes associ√©s / The information is added to the associated column names / Se a√±ade la informaci√≥n en los nombres de las columnas asociadas
    out = {"formation_type": formation_type}
    ords = ["1st","2nd","3rd","4th","5th","6th","7th","8th","9th","10th","11th"]
    for i, sfx in enumerate(ords, start=1):
        nm, ps = players[i-1]
        out[f"{sfx}_player_name"] = nm
        out[f"{sfx}_player_position"] = ps
    return out

## Partie pour choisir les saisons √† scraper / Off to choose which seasons to scrap / Partida para elegir las temporadas que se van a descartar

# Lecture de la liste de saisons / Reading the list of seasons / Lectura de la lista de temporadas
try:
    from IPython.display import display
except Exception:
    display = print

try:
    DATA_DIR
except NameError:
    DATA_DIR = Path("data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

SEASON_CSV = DATA_DIR / "season.csv"
SEASON_COLS = ["country", "championship_name", "season_name", "id_season", "link_url_opta", "link_url_whoscored"]

# R√©cup√©ration des indices / Recovery of indices / Recuperaci√≥n de los √≠ndices
def _parse_multi_indices(raw: str, n: int) -> List[int]:
    raw = (raw or "").strip().lower()
    if raw in {"all", "*", "tout", "tous", "toutes"}:
        return list(range(1, n + 1))

    tokens = re.split(r"[,\s]+", raw)
    sel = set()
    for tok in tokens:
        if not tok:
            continue
        m = re.match(r"^(\d+)\s*-\s*(\d+)$", tok)
        if m:
            a, b = int(m.group(1)), int(m.group(2))
            if a > b:
                a, b = b, a
            for k in range(a, b + 1):
                if 1 <= k <= n:
                    sel.add(k)
        else:
            if tok.isdigit():
                k = int(tok)
                if 1 <= k <= n:
                    sel.add(k)
    return sorted(sel)
    
# Fonction pour lire season.csv / Function to read season.csv / Funci√≥n para leer season.csv
def _read_season_catalog(path: Path) -> pd.DataFrame:
    # Si le fichier n'existe pas, on le cr√©e / If the file does not exist, it is created / Si el archivo no existe, se crea.
    if not path.exists():
        return pd.DataFrame(columns=SEASON_COLS)
    df = pd.read_csv(path, dtype=str, keep_default_na=False)
    for c in SEASON_COLS:
        if c not in df.columns:
            df[c] = ""
    return df[SEASON_COLS]

# R√©cup√®re toutes les saisons disponibles / Collect all available seasons / Recupera todas las temporadas disponibles
def choose_seasons_all(path: Path = SEASON_CSV) -> List[Tuple[int, str, pd.Series]]:
 
    df = _read_season_catalog(path)
    if df.empty:
        raise RuntimeError(
            f"Aucune saison trouv√©e dans {path}. "
            f"Ajoute des lignes avec colonnes {SEASON_COLS}."
        )

    selections: List[Tuple[int, str, pd.Series]] = []
    for i, row in df.iterrows():
        try:
            id_season = int(row["id_season"])
        except Exception:
            print(f"[WARN] id_season invalide √† la ligne {i+1}: {row.get('id_season')!r}")
            continue

        link_url = str(row.get("link_url_whoscored", "")).strip()
        if not link_url:
            print(f"[WARN] link_url_whoscored manquant √† la ligne {i+1} pour "
                  f"{row.get('country','?')} ‚Äî {row.get('championship_name','?')} {row.get('season_name','?')}")
            continue

        print(f"‚Üí Saison {row.get('country','?')} ‚Äî {row.get('championship_name','?')} "
              f"{row.get('season_name','?')} (id={id_season})")
        selections.append((id_season, link_url, row))

    if not selections:
        raise RuntimeError("Aucune saison exploitable (toutes les lignes √©taient invalides/incompl√®tes).")
    return selections


TEAMS_STATS_OTHER_PATH = DATA_DIR / "teams_stats_other.csv"

# Si teams_stats_other.csv contient d√©j√† des √©quipes pour id_season, on les charge et on retourne, sinon on scrape les informations associ√©es / If teams_stats_other.csv already contains teams for id_season, we load them and return; otherwise, we scrape the associated information / Si teams_stats_other.csv ya contiene equipos para id_season, los cargamos y los devolvemos; de lo contrario, extraemos la informaci√≥n asociada
def ensure_df_teams_for_season(driver, id_season: int, _row: pd.Series,
                               path: Path = TEAMS_STATS_OTHER_PATH) -> pd.DataFrame:
    id_season_str = str(id_season)

    # Si on a d√©j√† les donn√©es, on ne change pas / If we already have the data, we don't change it / Si ya tenemos los datos, no cambiamos nada
    if path.exists():
        df_all = pd.read_csv(path, dtype=str, keep_default_na=False)
        if "id_season" in df_all.columns and (df_all["id_season"] == id_season_str).any():
            df_season = df_all[df_all["id_season"] == id_season_str].copy()
            if "team_id" in df_season.columns:
                df_season["team_id"] = pd.to_numeric(df_season["team_id"], errors="coerce").astype("Int64")
            return df_season.reset_index(drop=True)

    # Sinon on scrape les donn√©es / Si no, recopilamos los datos
    teams_info = extract_team_basic_info_from_summary(driver, timeout=2)

    df_season = pd.DataFrame(teams_info)
    # On sp√©cifie la recherche sur les informations sur l'identifiant, le nom et l'url de l'√©quipe / We specify the search for information on the team's ID, name and URL / Se especifica la b√∫squeda de informaci√≥n sobre el identificador, el nombre y la URL del equipo
    for c in ["team_id", "team_name", "team_url"]:
        if c not in df_season.columns:
            df_season[c] = ""
    df_season["team_id"] = pd.to_numeric(df_season["team_id"], errors="coerce").astype("Int64")

    # On ajoute les informations de la saison et du championnat / Add the season and championship information / Se a√±ade la informaci√≥n sobre la temporada y el campeonato
    df_season.insert(0, "id_season", id_season_str)
    df_season.insert(1, "season_name", _row.get("season_name"))
    df_season.insert(2, "country", _row.get("country"))
    df_season.insert(3, "championship_name", _row.get("championship_name"))

    # On ajoute cela dans le fichier / Add this to the file / A√±adimos esto al archivo
    if path.exists():
        df_all = pd.read_csv(path, dtype=str, keep_default_na=False)
    else:
        df_all = pd.DataFrame(columns=df_season.columns)

    # On harmonise les colonnes / We harmonise the columns / Se armonizan las columnas
    for c in df_season.columns:
        if c not in df_all.columns: df_all[c] = ""
    for c in df_all.columns:
        if c not in df_season.columns: df_season[c] = ""

    df_all = pd.concat([df_all, df_season], ignore_index=True)
    df_all["id_season"] = df_all["id_season"].astype(str)
    df_all["team_id"] = pd.to_numeric(df_all["team_id"], errors="coerce").astype("Int64")
    df_all = df_all.drop_duplicates(subset=["id_season","team_id"], keep="last").reset_index(drop=True)
    df_all.to_csv(path, index=False)

    return df_season.reset_index(drop=True)

# Fonction main / Function main / Funci√≥n main
def run_scrape_whoscored(headed: bool = True):
    # S√©lection des saisons / Season selection / Selecci√≥n de temporadas
    selections = choose_seasons_all()
    if not selections:
        print("Aucune saison √† scraper, arr√™t.")
        return

    # Driver / Driver / Controlador
    try:
        driver = make_driver(headed=headed)
    except NameError:
        chrome_options = Options()
        if not headed:
            chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--window-size=1366,900")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option("useAutomationExtension", False)
        driver = webdriver.Chrome(options=chrome_options)

    try:
        for (id_season, season_url, _row) in selections:
            print("\n" + "=" * 70)
            print(f"Scraping saison {id_season} ‚Üí {season_url}")
            print("=" * 70)

            try:
                # Ouvrir la page saison / Open the page season / Abrir la p√°gina de temporada
                get_with_retries(driver, season_url, tries=3, sleep_s=2.0)
                time.sleep(1.0)

                # Cookies / Cookies / Galletas
                try:
                    handle_cookies(driver, accept=False, timeout=2)
                    #print("Page des cookies ferm√©e")
                except Exception:
                    pass

                # Aller sur "Statistiques des √âquipes" / Go to ‚ÄòTeam Statistics‚Äô / Ir a ¬´Estad√≠sticas de los equipos¬ª
                click_team_statistics(driver, timeout=5)
                #print("Onglet 'Statistiques des √âquipes' ouvert")

                # R√©cup√©ration (ou chargement) des √©quipes pour la saison / Recovery (or loading) of teams for the season / Recuperaci√≥n (o carga) de los equipos para la temporada
                df_teams = ensure_df_teams_for_season(
                    driver, id_season, _row, path=DATA_DIR / "teams_stats_other.csv"
                )

                # Pour chaque √©quipe : on r√©cup√®re le Top5 + Formation/XI / For each team: we collect the Top 5 + Line-up/XI / Para cada equipo: se recupera el Top 5 + Formaci√≥n/XI.
                rows_out = []
                ords = ["1st","2nd","3rd","4th","5th","6th","7th","8th","9th","10th","11th"]
                top5_keys = ["1st_best_player","2nd_best_player","3rd_best_player","4th_best_player","5th_best_player"]

                for _, r in df_teams.iterrows():
                    team_url = r["team_url"]

                    # TOP 5 / TOP 5 / TOP 5
                    try:
                        top5 = extract_top5_ratings_from_team(driver, team_url, timeout=8)
                    except Exception as e:
                        print(f"[WARN] top5: {r.get('team_name','?')}: {type(e).__name__}: {e}")
                        top5 = {k: "" for k in top5_keys}

                    # FORMATION + XI / Line-up + XI / Formaci√≥n/XI
                    try:
                        xi = extract_formation_and_xi_from_team(driver, team_url, timeout=8, reuse_current=True)
                    except Exception as e:
                        print(f"[WARN] formation/XI: {r.get('team_name','?')}: {type(e).__name__}: {e}")
                        xi = {"formation_type": ""}
                        for sfx in ords:
                            xi[f"{sfx}_player_name"] = ""
                            xi[f"{sfx}_player_position"] = ""

                    row_out = {**r.to_dict(), **top5, **xi}
                    rows_out.append(row_out)

                    # V√©rification / Verification / Verificaci√≥n
                    top5_full = all(row_out[k] for k in top5_keys)
                    xi_full = bool(row_out.get("formation_type")) and all(
                        row_out[f"{s}_player_name"] and row_out[f"{s}_player_position"] for s in ords
                    )
                    print(f"‚úî OK ‚Äî {row_out.get('team_name','?')}" if (top5_full and xi_full)
                          else f"‚úñ Incomplet ‚Äî {row_out.get('team_name','?')}")

                    time.sleep(0.02)

                df_out = pd.DataFrame(rows_out)

                # Sauvegarde / Save / Copia de seguridad
                csv_path = DATA_DIR / "teams_stats_other.csv"
                if csv_path.exists():
                    all_prev = pd.read_csv(csv_path, dtype=str, keep_default_na=False)
                else:
                    all_prev = pd.DataFrame(columns=df_out.columns)

                for c in df_out.columns:
                    if c not in all_prev.columns: all_prev[c] = ""
                for c in all_prev.columns:
                    if c not in df_out.columns: df_out[c] = ""

                all_cat = pd.concat([all_prev, df_out], ignore_index=True)
                all_cat["id_season"] = all_cat["id_season"].astype(str)
                all_cat["team_id"] = pd.to_numeric(all_cat["team_id"], errors="coerce").astype("Int64")
                all_cat = all_cat.drop_duplicates(subset=["id_season", "team_id"], keep="last").reset_index(drop=True)
                all_cat.to_csv(csv_path, index=False)
                print(f"‚Üí Mise √† jour √©crite dans {csv_path}")

            except Exception as e:
                print(f"[WARN] √âchec sur la saison {id_season}: {type(e).__name__}: {e}")
    finally:
        try:
            driver.quit()
        except Exception:
            pass



# Execution du web scraping pour la saison de son choix / Execution of web scraping for the season of your choice / Ejecuci√≥n del web scraping para la temporada que elija
if __name__ == "__main__":
    run_scrape_whoscored(headed=False)
